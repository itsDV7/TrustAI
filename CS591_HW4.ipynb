{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.linear_model import Ridge, Lasso, lars_path\n",
        "from skimage.segmentation import quickshift\n",
        "from sklearn.metrics import pairwise_distances\n",
        "from sklearn.utils import check_random_state\n",
        "import torch\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.models as models\n",
        "from PIL import Image\n",
        "import json\n",
        "import os\n",
        "from scipy import stats\n",
        "from typing import Dict, List, Tuple\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "\n",
        "class LimeImageExplainer:\n",
        "    def __init__(self, kernel_width=0.25):\n",
        "        self.kernel_width = kernel_width\n",
        "\n",
        "    def _generate_lars_path(self, weighted_data, weighted_labels):\n",
        "        alphas, _, coef_path = lars_path(weighted_data, weighted_labels, method='lasso')\n",
        "        feature_sets = []\n",
        "        scores = []\n",
        "\n",
        "        for coef in coef_path.T:\n",
        "            nonzero_features = np.nonzero(coef)[0]\n",
        "            feature_sets.append(nonzero_features)\n",
        "\n",
        "            if len(nonzero_features) > 0:\n",
        "                ridge = Ridge(alpha=0.01)\n",
        "                ridge.fit(weighted_data[:, nonzero_features], weighted_labels)\n",
        "                scores.append(ridge.score(weighted_data[:, nonzero_features], weighted_labels))\n",
        "            else:\n",
        "                scores.append(float('-inf'))\n",
        "\n",
        "            if len(nonzero_features) >= 10:\n",
        "                break\n",
        "\n",
        "        return feature_sets, scores\n",
        "\n",
        "    def _fit_lasso(self, data, labels, weights, num_features):\n",
        "        weighted_data = data * np.sqrt(weights)[:, np.newaxis]\n",
        "        weighted_labels = labels * np.sqrt(weights)\n",
        "\n",
        "        feature_sets, scores = self._generate_lars_path(weighted_data, weighted_labels)\n",
        "\n",
        "        best_score = float('-inf')\n",
        "        best_features = None\n",
        "\n",
        "        for features, score in zip(feature_sets, scores):\n",
        "            if len(features) <= num_features and score > best_score:\n",
        "                best_score = score\n",
        "                best_features = features\n",
        "\n",
        "        ridge = Ridge(alpha=0.01, fit_intercept=True)\n",
        "        ridge.fit(weighted_data[:, best_features], weighted_labels)\n",
        "\n",
        "        coef = np.zeros(data.shape[1])\n",
        "        coef[best_features] = ridge.coef_\n",
        "\n",
        "        return coef\n",
        "\n",
        "    def explain_instance(self, image, classifier_fn, labels=(1,), num_samples=1000, num_features=10, batch_size=10):\n",
        "        segments = quickshift(image, kernel_size=4, max_dist=200, ratio=0.2)\n",
        "        num_segments = np.unique(segments).shape[0]\n",
        "\n",
        "        random_state = check_random_state(None)\n",
        "        perturbations = random_state.randint(0, 2, num_samples * num_segments)\\\n",
        "                       .reshape((num_samples, num_segments))\n",
        "\n",
        "        perturbed_images = []\n",
        "        for pert in perturbations:\n",
        "            perturbed = image.copy()\n",
        "            for segment_id in range(num_segments):\n",
        "                if pert[segment_id] == 0:\n",
        "                    perturbed[segments == segment_id] = (\n",
        "                        np.mean(image[segments == segment_id], axis=0))\n",
        "            perturbed_images.append(perturbed)\n",
        "\n",
        "        predictions = []\n",
        "        for i in range(0, len(perturbed_images), batch_size):\n",
        "            batch = np.array(perturbed_images[i:i+batch_size])\n",
        "            preds = classifier_fn(batch)\n",
        "            predictions.extend(preds.numpy())\n",
        "        predictions = np.array(predictions)\n",
        "\n",
        "        distances = pairwise_distances(\n",
        "            perturbations,\n",
        "            perturbations[0].reshape(1, -1),\n",
        "            metric='cosine'\n",
        "        ).ravel()\n",
        "\n",
        "        weights = np.sqrt(np.exp(-(distances ** 2) / self.kernel_width ** 2))\n",
        "\n",
        "        explanations = {}\n",
        "        for label in labels:\n",
        "            label_score = predictions[:, label]\n",
        "            feature_weights = self._fit_lasso(perturbations, label_score, weights, num_features)\n",
        "\n",
        "            explanations[label] = {\n",
        "                'segments': segments,\n",
        "                'feature_weights': feature_weights,\n",
        "                'predicted_value': predictions[0, label]\n",
        "            }\n",
        "\n",
        "        return explanations\n",
        "\n",
        "\n",
        "# Set device\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# Model setup\n",
        "model = models.resnet18(pretrained=True)\n",
        "model = model.to(device)\n",
        "model.eval()\n",
        "\n",
        "# Define preprocessing\n",
        "preprocess = transforms.Compose([\n",
        "    transforms.Resize(256),\n",
        "    transforms.CenterCrop(224),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(\n",
        "        mean=[0.485, 0.456, 0.406],\n",
        "        std=[0.229, 0.224, 0.225]\n",
        "    )\n",
        "])\n",
        "\n",
        "# Load the ImageNet class index mapping\n",
        "with open(\"imagenet_class_index.json\") as f:\n",
        "    class_idx = json.load(f)\n",
        "idx2label = [class_idx[str(k)][1] for k in range(len(class_idx))]\n",
        "idx2synset = [class_idx[str(k)][0] for k in range(len(class_idx))]\n",
        "id2label = {v[0]: v[1] for v in class_idx.values()}\n",
        "\n",
        "\n",
        "def process_single_image(image_path):\n",
        "    input_image = Image.open(image_path).convert('RGB')\n",
        "    input_image = input_image.resize((224, 224), Image.BILINEAR)\n",
        "\n",
        "    np_image = np.array(input_image)\n",
        "\n",
        "    input_tensor = preprocess(input_image)\n",
        "    input_batch = input_tensor.unsqueeze(0)\n",
        "    input_batch = input_batch.to(device)\n",
        "\n",
        "    return np_image, input_batch\n",
        "\n",
        "\n",
        "def classifier_fn(perturbed_images):\n",
        "    processed_images = []\n",
        "\n",
        "    for img in perturbed_images:\n",
        "        try:\n",
        "            if torch.is_tensor(img):\n",
        "                img = img.cpu().numpy()\n",
        "\n",
        "            if img.max() <= 1.0:\n",
        "                img = (img * 255).astype(np.uint8)\n",
        "            else:\n",
        "                img = img.astype(np.uint8)\n",
        "\n",
        "            pil_image = Image.fromarray(img)\n",
        "            tensor = preprocess(pil_image)\n",
        "            processed_images.append(tensor)\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error processing image in classifier_fn: {str(e)}\")\n",
        "            continue\n",
        "\n",
        "    batch = torch.stack(processed_images)\n",
        "    batch = batch.to(device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        outputs = model(batch)\n",
        "        probs = torch.nn.functional.softmax(outputs, dim=1)\n",
        "\n",
        "    return probs.cpu()\n",
        "\n",
        "\n",
        "def visualize_explanation(image, explanation, label):\n",
        "    segments = explanation['segments']\n",
        "    feature_weights = explanation['feature_weights']\n",
        "\n",
        "    mask = np.zeros(segments.shape, dtype=bool)\n",
        "\n",
        "    for segment_id, weight in enumerate(feature_weights):\n",
        "        if weight != 0:\n",
        "            mask[segments == segment_id] = True\n",
        "\n",
        "    visualization = np.full_like(image, 128)\n",
        "    visualization[mask] = image[mask]\n",
        "\n",
        "    return visualization\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    imagenet_path = '/content/imagenet_samples'\n",
        "    image_paths = [os.path.join(imagenet_path, f) for f in os.listdir(imagenet_path)\n",
        "                  if f.lower().endswith(('.jpg', '.jpeg', '.png', '.bmp', '.gif'))]\n",
        "\n",
        "    explainer = LimeImageExplainer()\n",
        "\n",
        "    for img_path in image_paths:\n",
        "        try:\n",
        "            np_image, input_batch = process_single_image(img_path)\n",
        "\n",
        "            with torch.no_grad():\n",
        "                output = model(input_batch)\n",
        "\n",
        "            _, predicted_idx = torch.max(output, 1)\n",
        "            predicted_idx = predicted_idx.item()\n",
        "            predicted_label = idx2label[predicted_idx]\n",
        "\n",
        "            print(f\"Processed {img_path}: Predicted as {predicted_label}\")\n",
        "\n",
        "            explanation = explainer.explain_instance(\n",
        "                np_image,\n",
        "                classifier_fn,\n",
        "                labels=[predicted_idx],\n",
        "                num_samples=50,\n",
        "                num_features=10,\n",
        "                batch_size=10\n",
        "            )\n",
        "\n",
        "            mask_viz = visualize_explanation(\n",
        "                np_image,\n",
        "                explanation[predicted_idx],\n",
        "                predicted_idx\n",
        "            )\n",
        "\n",
        "            plt.figure(figsize=(12, 6))\n",
        "            plt.subplot(1, 2, 1)\n",
        "            plt.imshow(np_image)\n",
        "            plt.title(f'Original: {predicted_label}')\n",
        "            plt.axis('off')\n",
        "\n",
        "            plt.subplot(1, 2, 2)\n",
        "            plt.imshow(mask_viz)\n",
        "            plt.title('LIME Explanation')\n",
        "            plt.axis('off')\n",
        "\n",
        "            plt.tight_layout()\n",
        "            save_path = f'LIME_{os.path.basename(img_path)}'\n",
        "            plt.savefig(save_path, bbox_inches='tight', dpi=150)\n",
        "            plt.close()\n",
        "        except Exception as e:\n",
        "            print(f\"Error processing {img_path}: {str(e)}\")\n",
        "            import traceback\n",
        "            traceback.print_exc()\n",
        "            continue"
      ],
      "metadata": {
        "id": "Hf6QzXDUUEEp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the pre-trained ResNet18 model\n",
        "model = models.resnet18(pretrained=True)\n",
        "model.eval()  # Set model to evaluation mode\n",
        "\n",
        "# Define the image preprocessing transformations\n",
        "preprocess = transforms.Compose([\n",
        "    transforms.Resize(256),\n",
        "    transforms.CenterCrop(224),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(\n",
        "        mean=[0.485, 0.456, 0.406],\n",
        "        std=[0.229, 0.224, 0.225]\n",
        "    )\n",
        "])\n",
        "\n",
        "# Load the ImageNet class index mapping\n",
        "with open(\"imagenet_class_index.json\") as f:\n",
        "    class_idx = json.load(f)\n",
        "idx2label = [class_idx[str(k)][1] for k in range(len(class_idx))]\n",
        "idx2synset = [class_idx[str(k)][0] for k in range(len(class_idx))]\n",
        "id2label = {v[0]: v[1] for v in class_idx.values()}\n",
        "\n",
        "\n",
        "class SmoothGrad:\n",
        "    def __init__(self, model: torch.nn.Module,\n",
        "                 device: str = 'cuda' if torch.cuda.is_available() else 'cpu'):\n",
        "        self.model = model.to(device)\n",
        "        self.device = device\n",
        "\n",
        "    def generate_noise(self, image: torch.Tensor, noise_level: float):\n",
        "        return torch.normal(\n",
        "            mean=0,\n",
        "            std=noise_level,\n",
        "            size=image.shape,\n",
        "            device=self.device\n",
        "        )\n",
        "\n",
        "    def get_gradients(self, image: torch.Tensor, target_class: int):\n",
        "        image.requires_grad_()\n",
        "        output = self.model(image)\n",
        "        score = output[:, target_class]\n",
        "        self.model.zero_grad()\n",
        "        score.backward()\n",
        "\n",
        "        return image.grad.data\n",
        "\n",
        "    def __call__(self, image: torch.Tensor, n_samples: int = 50, noise_level: float = 0.1):\n",
        "        if image.dim() == 3:\n",
        "            image = image.unsqueeze(0)\n",
        "        image = image.to(self.device)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            output = self.model(image)\n",
        "            target_class = output.argmax(dim=1).item()\n",
        "\n",
        "        image_range = image.max() - image.min()\n",
        "        noise_scale = noise_level * image_range\n",
        "\n",
        "        accumulated_grads = torch.zeros_like(image)\n",
        "\n",
        "        for _ in range(n_samples):\n",
        "            noise = self.generate_noise(image, noise_scale)\n",
        "            noisy_image = image + noise\n",
        "\n",
        "            grads = self.get_gradients(noisy_image, target_class)\n",
        "            accumulated_grads += grads\n",
        "\n",
        "        smoothed_grads = accumulated_grads / n_samples\n",
        "\n",
        "        return smoothed_grads, target_class\n",
        "\n",
        "def visualize_sensitivity_map(sensitivity_map: torch.Tensor, original_image: Image, predicted_label: str):\n",
        "    sensitivity = sensitivity_map.cpu().numpy()[0].transpose(1, 2, 0)\n",
        "    sensitivity = np.abs(sensitivity)\n",
        "    sensitivity = (sensitivity - sensitivity.min()) / (sensitivity.max() - sensitivity.min())\n",
        "    sensitivity = sensitivity.max(axis=2)\n",
        "\n",
        "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 5))\n",
        "\n",
        "    ax1.imshow(original_image)\n",
        "    ax1.set_title('Original Image')\n",
        "    ax1.axis('off')\n",
        "\n",
        "    ax2.imshow(sensitivity, cmap='hot')\n",
        "    ax2.set_title(f'SmoothGrad Sensitivity Map\\nPredicted: {predicted_label}')\n",
        "    ax2.axis('off')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    return fig\n",
        "\n",
        "\n",
        "smooth_grad = SmoothGrad(model)\n",
        "\n",
        "imagenet_path = './imagenet_samples'\n",
        "\n",
        "# List of image file paths\n",
        "image_paths = os.listdir(imagenet_path)\n",
        "\n",
        "for img_path in image_paths:\n",
        "    full_path = os.path.join(imagenet_path, img_path)\n",
        "    try:\n",
        "        input_image = Image.open(full_path).convert('RGB')\n",
        "        input_tensor = preprocess(input_image)\n",
        "\n",
        "        sensitivity_map, predicted_idx = smooth_grad(\n",
        "            input_tensor,\n",
        "            n_samples=50,\n",
        "            noise_level=0.1\n",
        "        )\n",
        "\n",
        "        predicted_label = idx2label[predicted_idx]\n",
        "\n",
        "        fig = visualize_sensitivity_map(sensitivity_map, input_image, predicted_label)\n",
        "        output_filename = f'smoothgrad_{os.path.splitext(img_path)[0]}.png'\n",
        "        fig.savefig(output_filename)\n",
        "        plt.close(fig)\n",
        "\n",
        "        print(f\"Processed {img_path}: Predicted as {predicted_label}\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error processing {img_path}: {str(e)}\")"
      ],
      "metadata": {
        "id": "HeGxAI2z3CxP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ExplanationCorrelation:\n",
        "    def get_feature_ranking(explanation: Dict):\n",
        "        weights = np.abs(explanation['feature_weights'])\n",
        "        rankings = stats.rankdata(-weights)\n",
        "\n",
        "        return rankings\n",
        "\n",
        "    def calculate_correlations(rankings1: np.ndarray, rankings2: np.ndarray):\n",
        "        kendall_tau, kendall_p = stats.kendalltau(rankings1, rankings2)\n",
        "        spearman_rho, spearman_p = stats.spearmanr(rankings1, rankings2)\n",
        "\n",
        "        return kendall_tau, kendall_p, spearman_rho, spearman_p\n",
        "\n",
        "    def compare_explanations(explanation1: Dict,\n",
        "                             explanation2: Dict,\n",
        "                             method1_name: str,\n",
        "                             method2_name: str):\n",
        "\n",
        "        rankings1 = ExplanationCorrelation.get_feature_ranking(explanation1)\n",
        "        rankings2 = ExplanationCorrelation.get_feature_ranking(explanation2)\n",
        "        kendall_tau, kendall_p, spearman_rho, spearman_p = (\n",
        "            ExplanationCorrelation.calculate_correlations(rankings1, rankings2)\n",
        "        )\n",
        "\n",
        "        return {\n",
        "            'method1': method1_name,\n",
        "            'method2': method2_name,\n",
        "            'kendall_tau': kendall_tau,\n",
        "            'kendall_p_value': kendall_p,\n",
        "            'spearman_rho': spearman_rho,\n",
        "            'spearman_p_value': spearman_p\n",
        "        }\n",
        "\n",
        "\n",
        "def visualize_correlation_matrices(kendall_matrix: np.ndarray, spearman_matrix: np.ndarray, method_names: List[str]):\n",
        "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))\n",
        "\n",
        "    sns.heatmap(kendall_matrix,\n",
        "                annot=True,\n",
        "                cmap='RdBu',\n",
        "                vmin=-1,\n",
        "                vmax=1,\n",
        "                xticklabels=method_names,\n",
        "                yticklabels=method_names,\n",
        "                ax=ax1)\n",
        "    ax1.set_title('Kendall Tau Correlations')\n",
        "\n",
        "    sns.heatmap(spearman_matrix,\n",
        "                annot=True,\n",
        "                cmap='RdBu',\n",
        "                vmin=-1,\n",
        "                vmax=1,\n",
        "                xticklabels=method_names,\n",
        "                yticklabels=method_names,\n",
        "                ax=ax2)\n",
        "    ax2.set_title('Spearman Rank Correlations')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    return fig\n",
        "\n",
        "def convert_smoothgrad_to_segments(smoothgrad_grads: torch.Tensor, segments: np.ndarray):\n",
        "\n",
        "    grads = np.abs(smoothgrad_grads.cpu().numpy()[0])\n",
        "    grads = grads.mean(axis=0)\n",
        "\n",
        "    unique_segments = np.unique(segments)\n",
        "    num_segments = len(unique_segments)\n",
        "\n",
        "    feature_weights = np.zeros(num_segments)\n",
        "    for i, segment_id in enumerate(unique_segments):\n",
        "        segment_mask = (segments == segment_id)\n",
        "        feature_weights[i] = grads[segment_mask].mean()\n",
        "\n",
        "    return {\n",
        "        'segments': segments,\n",
        "        'feature_weights': feature_weights\n",
        "    }\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "\n",
        "    image_path = \"/content/imagenet_samples/mountain_bike.JPEG\"\n",
        "    np_image, input_batch = process_single_image(image_path)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        output = model(input_batch)\n",
        "        _, predicted_idx = torch.max(output, 1)\n",
        "        predicted_idx = predicted_idx.item()\n",
        "\n",
        "    lime_explainer = LimeImageExplainer()\n",
        "    lime_explanation = lime_explainer.explain_instance(\n",
        "        np_image,\n",
        "        classifier_fn,\n",
        "        labels=[predicted_idx],\n",
        "        num_samples=100,\n",
        "        num_features=10\n",
        "    )\n",
        "    segments = lime_explanation[predicted_idx]['segments']\n",
        "\n",
        "    smooth_grad = SmoothGrad(model)\n",
        "    smoothgrad_grads, _ = smooth_grad(\n",
        "        input_batch,\n",
        "        n_samples=50,\n",
        "        noise_level=0.1\n",
        "    )\n",
        "    smoothgrad_explanation = convert_smoothgrad_to_segments(\n",
        "        smoothgrad_grads,\n",
        "        segments\n",
        "    )\n",
        "\n",
        "    explanations = {\n",
        "        'LIME': lime_explanation[predicted_idx],\n",
        "        'SmoothGrad': smoothgrad_explanation\n",
        "    }\n",
        "\n",
        "\n",
        "    kendall_matrix = np.ones((2, 2))\n",
        "    spearman_matrix = np.ones((2, 2))\n",
        "\n",
        "    results = ExplanationCorrelation.compare_explanations(\n",
        "        explanations['LIME'],\n",
        "        explanations['SmoothGrad'],\n",
        "        'LIME',\n",
        "        'SmoothGrad'\n",
        "    )\n",
        "\n",
        "    kendall_matrix[0, 1] = results['kendall_tau']\n",
        "    kendall_matrix[1, 0] = results['kendall_tau']\n",
        "\n",
        "    spearman_matrix[0, 1] = results['spearman_rho']\n",
        "    spearman_matrix[1, 0] = results['spearman_rho']\n",
        "\n",
        "    fig = visualize_correlation_matrices(\n",
        "        kendall_matrix,\n",
        "        spearman_matrix,\n",
        "        list(explanations.keys())\n",
        "    )\n",
        "    plt.show()\n",
        "\n",
        "    print(\"\\nresults:\")\n",
        "    for key, value in results.items():\n",
        "        if isinstance(value, float):\n",
        "            print(f\"{key}: {value:.4f}\")\n",
        "        else:\n",
        "            print(f\"{key}: {value}\")\n",
        "\n",
        "    def visualize_segmented_explanations(original_image: np.ndarray, lime_exp: Dict, smoothgrad_exp: Dict):\n",
        "\n",
        "        fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
        "\n",
        "        axes[0].imshow(original_image)\n",
        "        axes[0].set_title('Original Image')\n",
        "        axes[0].axis('off')\n",
        "\n",
        "        segments = lime_exp['segments']\n",
        "        lime_mask = np.zeros_like(segments, dtype=float)\n",
        "        for segment_id, weight in enumerate(lime_exp['feature_weights']):\n",
        "            lime_mask[segments == segment_id] = abs(weight)\n",
        "        axes[1].imshow(lime_mask, cmap='gray')\n",
        "        axes[1].set_title('LIME Explanation')\n",
        "        axes[1].axis('off')\n",
        "\n",
        "        smoothgrad_mask = np.zeros_like(segments, dtype=float)\n",
        "        for segment_id, weight in enumerate(smoothgrad_exp['feature_weights']):\n",
        "            smoothgrad_mask[segments == segment_id] = abs(weight)\n",
        "        axes[2].imshow(smoothgrad_mask, cmap='gray')\n",
        "        axes[2].set_title('Segmented SmoothGrad')\n",
        "        axes[2].axis('off')\n",
        "\n",
        "        plt.tight_layout()\n",
        "        return fig\n",
        "\n",
        "    fig = visualize_segmented_explanations(\n",
        "        np_image,\n",
        "        explanations['LIME'],\n",
        "        explanations['SmoothGrad']\n",
        "    )\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "iDhxJ0vaUGA_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "from typing import Optional, Tuple\n",
        "from tqdm import tqdm\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "\n",
        "class PGDExplanationAttack:\n",
        "    def __init__(\n",
        "        self,\n",
        "        model: torch.nn.Module,\n",
        "        num_steps: int = 5,\n",
        "        step_size: float = 1/255,\n",
        "        initial_explanation_weight: float = 1.0,\n",
        "        initial_prediction_weight: float = 100.0,\n",
        "        device: str = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "    ):\n",
        "        self.model = model.to(device)\n",
        "        self.num_steps = num_steps\n",
        "        self.step_size = step_size\n",
        "        self.explanation_weight = initial_explanation_weight\n",
        "        self.prediction_weight = initial_prediction_weight\n",
        "        self.device = device\n",
        "\n",
        "    def get_smoothgrad_explanation(\n",
        "        self,\n",
        "        image: torch.Tensor,\n",
        "        n_samples: int = 50,\n",
        "        noise_level: float = 0.1,\n",
        "        target_class: Optional[int] = None\n",
        "    ):\n",
        "        accumulated_grads = torch.zeros_like(image).to(self.device)\n",
        "\n",
        "        image_range = image.max() - image.min()\n",
        "        noise_scale = noise_level * image_range\n",
        "\n",
        "        if target_class is None:\n",
        "            with torch.no_grad():\n",
        "                output = self.model(image)\n",
        "                target_class = output.argmax(dim=1).item()\n",
        "\n",
        "        for _ in range(n_samples):\n",
        "            noise = torch.randn_like(image).to(self.device) * noise_scale\n",
        "            noisy_image = image.clone() + noise\n",
        "            noisy_image.requires_grad_(True)\n",
        "\n",
        "            output = self.model(noisy_image)\n",
        "            score = output[:, target_class]\n",
        "\n",
        "            grad = torch.autograd.grad(score, noisy_image,\n",
        "                                     create_graph=True,\n",
        "                                     retain_graph=True)[0]\n",
        "\n",
        "            accumulated_grads += grad\n",
        "\n",
        "        return accumulated_grads / n_samples\n",
        "\n",
        "    def prediction_loss(\n",
        "        self,\n",
        "        original_output: torch.Tensor,\n",
        "        perturbed_output: torch.Tensor,\n",
        "        target_class: int\n",
        "    ):\n",
        "        orig_probs = F.softmax(original_output, dim=1)\n",
        "        pert_probs = F.softmax(perturbed_output, dim=1)\n",
        "\n",
        "        target_prob_loss = F.mse_loss(pert_probs[:, target_class], orig_probs[:, target_class])\n",
        "\n",
        "        ranking_loss = torch.relu(\n",
        "            pert_probs.max(dim=1)[0] - pert_probs[:, target_class] + 0.1\n",
        "        ).mean()\n",
        "\n",
        "        logit_diff_loss = F.mse_loss(\n",
        "            perturbed_output[:, target_class] - perturbed_output,\n",
        "            original_output[:, target_class] - original_output\n",
        "        )\n",
        "\n",
        "        return target_prob_loss + ranking_loss + logit_diff_loss\n",
        "\n",
        "    def explanation_loss(\n",
        "        self,\n",
        "        original_exp: torch.Tensor,\n",
        "        perturbed_exp: torch.Tensor\n",
        "    ):\n",
        "        orig_norm = F.normalize(original_exp.view(original_exp.size(0), -1), dim=1)\n",
        "        pert_norm = F.normalize(perturbed_exp.view(perturbed_exp.size(0), -1), dim=1)\n",
        "\n",
        "        cos_sim = (orig_norm * pert_norm).sum(dim=1)\n",
        "        cos_loss = -torch.mean((1 - cos_sim))\n",
        "\n",
        "        mse_loss = F.mse_loss(orig_norm, pert_norm)\n",
        "\n",
        "        return cos_loss + mse_loss\n",
        "\n",
        "    def attack(\n",
        "        self,\n",
        "        image: torch.Tensor,\n",
        "        epsilon: float,\n",
        "    ):\n",
        "        if image.dim() == 3:\n",
        "            image = image.unsqueeze(0)\n",
        "        image = image.to(self.device)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            original_output = self.model(image)\n",
        "            target_class = original_output.argmax(dim=1).item()\n",
        "\n",
        "        original_exp = self.get_smoothgrad_explanation(image, target_class=target_class)\n",
        "\n",
        "        adv_image = image.clone().detach()\n",
        "        best_adv_image = adv_image.clone()\n",
        "        best_exp_diff = -float('inf')\n",
        "\n",
        "        pred_weight = self.prediction_weight\n",
        "        exp_weight = self.explanation_weight\n",
        "\n",
        "        for step in tqdm(range(self.num_steps), desc=\"PGD Attack\"):\n",
        "            adv_image.requires_grad_(True)\n",
        "\n",
        "            current_exp = self.get_smoothgrad_explanation(adv_image, target_class=target_class)\n",
        "            current_output = self.model(adv_image)\n",
        "            current_pred = current_output.argmax(dim=1).item()\n",
        "\n",
        "            pred_loss = self.prediction_loss(original_output, current_output, target_class)\n",
        "            exp_loss = self.explanation_loss(original_exp, current_exp)\n",
        "\n",
        "            if current_pred != target_class:\n",
        "                pred_weight *= 2\n",
        "            else:\n",
        "                pred_weight = max(pred_weight * 0.9, self.prediction_weight)\n",
        "\n",
        "            total_loss = (exp_weight * exp_loss) + (pred_weight * pred_loss)\n",
        "\n",
        "            grad = torch.autograd.grad(total_loss, adv_image)[0]\n",
        "\n",
        "            with torch.no_grad():\n",
        "                adv_image = adv_image.detach() + self.step_size * grad.sign()\n",
        "                delta = torch.clamp(adv_image - image, -epsilon, epsilon)\n",
        "                adv_image = torch.clamp(image + delta, 0, 1).detach()\n",
        "\n",
        "                current_output = self.model(adv_image)\n",
        "                current_pred = current_output.argmax(dim=1).item()\n",
        "\n",
        "                if current_pred == target_class:\n",
        "                    exp_diff = -self.explanation_loss(original_exp, current_exp).item()\n",
        "                    if exp_diff > best_exp_diff:\n",
        "                        best_exp_diff = exp_diff\n",
        "                        best_adv_image = adv_image.clone()\n",
        "\n",
        "        return best_adv_image, target_class\n",
        "\n",
        "def visualize_results(\n",
        "    original_tensor: torch.Tensor,\n",
        "    adv_image: torch.Tensor,\n",
        "    original_exp: torch.Tensor,\n",
        "    perturbed_exp: torch.Tensor,\n",
        "    orig_class: str,\n",
        "    orig_conf: float,\n",
        "    adv_class: str,\n",
        "    adv_conf: float,\n",
        "    epsilon: float\n",
        "):\n",
        "    fig = plt.figure(figsize=(15, 5))\n",
        "\n",
        "    plt.subplot(2, 2, 1)\n",
        "    plt.imshow(torch.clamp(original_tensor.squeeze().permute(1,2,0).cpu(), 0, 1))\n",
        "    plt.title(f'Original Image\\n{orig_class} ({orig_conf:.1f}%)')\n",
        "    plt.axis('off')\n",
        "\n",
        "    plt.subplot(2, 2, 2)\n",
        "    plt.imshow(torch.abs(original_exp.squeeze()).sum(dim=0).cpu().detach(), cmap='hot')\n",
        "    plt.title('Original Explanation')\n",
        "    plt.axis('off')\n",
        "\n",
        "    plt.subplot(2, 2, 3)\n",
        "    plt.imshow(torch.clamp(adv_image.squeeze().permute(1,2,0).cpu(), 0, 1))\n",
        "    plt.title(f'Adversarial Image (ε={epsilon:.3f})\\n{adv_class} ({adv_conf:.1f}%)')\n",
        "    plt.axis('off')\n",
        "\n",
        "    plt.subplot(2, 2, 4)\n",
        "    plt.imshow(torch.abs(perturbed_exp.squeeze()).sum(dim=0).cpu().detach(), cmap='hot')\n",
        "    plt.title('Perturbed Explanation')\n",
        "    plt.axis('off')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    return fig\n",
        "\n",
        "def get_prediction(model, image_tensor):\n",
        "    with torch.no_grad():\n",
        "        output = model(image_tensor)\n",
        "        probabilities = F.softmax(output, dim=1)\n",
        "        pred_idx = output.argmax(dim=1).item()\n",
        "        confidence = probabilities[0][pred_idx].item() * 100\n",
        "        return idx2label[pred_idx], confidence, pred_idx\n",
        "\n",
        "def apply_pgd_attack(image_path: str, model, preprocess):\n",
        "    input_image = Image.open(image_path).convert('RGB')\n",
        "    input_tensor = preprocess(input_image)\n",
        "\n",
        "    attack = PGDExplanationAttack(\n",
        "        model,\n",
        "        num_steps=5,\n",
        "        step_size=1/255,\n",
        "        initial_explanation_weight=1.0,\n",
        "        initial_prediction_weight=100.0\n",
        "    )\n",
        "\n",
        "    epsilons = [2/255, 4/255, 8/255]\n",
        "    results = []\n",
        "    predicted_idx = None\n",
        "\n",
        "    for epsilon in epsilons:\n",
        "        adv_image, predicted_idx = attack.attack(input_tensor, epsilon=epsilon)\n",
        "        results.append((adv_image, predicted_idx))\n",
        "\n",
        "    return input_tensor, results, idx2label[predicted_idx]\n",
        "\n",
        "def main():\n",
        "    images_to_attack = []\n",
        "    for img_path in os.listdir(imagenet_path):\n",
        "        if os.path.isfile(os.path.join(imagenet_path, img_path)):\n",
        "            images_to_attack.append(img_path)\n",
        "\n",
        "    for img_path in images_to_attack:\n",
        "        print(f\"\\nProcessing {img_path}\")\n",
        "        image_path = os.path.join(imagenet_path, img_path)\n",
        "\n",
        "        try:\n",
        "            original_tensor, attack_results, _ = apply_pgd_attack(image_path, model, preprocess)\n",
        "\n",
        "            orig_class, orig_conf, orig_idx = get_prediction(model, original_tensor.unsqueeze(0))\n",
        "            print(f\"\\nOriginal Classification: {orig_class} ({orig_conf:.2f}% confidence)\")\n",
        "\n",
        "            attack = PGDExplanationAttack(model)\n",
        "\n",
        "            for epsilon, (adv_image, _) in zip([2/255, 4/255, 8/255], attack_results):\n",
        "                adv_class, adv_conf, adv_idx = get_prediction(model, adv_image)\n",
        "\n",
        "                if adv_idx == orig_idx:\n",
        "                    print(f\"\\nEpsilon = {epsilon:.4f}:\")\n",
        "                    print(f\"Adversarial Classification: {adv_class} ({adv_conf:.2f}% confidence)\")\n",
        "\n",
        "                    original_tensor_batch = original_tensor.unsqueeze(0) if original_tensor.dim() == 3 else original_tensor\n",
        "                    adv_image_batch = adv_image.unsqueeze(0) if adv_image.dim() == 3 else adv_image\n",
        "\n",
        "                    original_exp = attack.get_smoothgrad_explanation(original_tensor_batch)\n",
        "                    perturbed_exp = attack.get_smoothgrad_explanation(adv_image_batch)\n",
        "\n",
        "                    fig = visualize_results(\n",
        "                        original_tensor_batch, adv_image_batch,\n",
        "                        original_exp, perturbed_exp,\n",
        "                        orig_class, orig_conf,\n",
        "                        adv_class, adv_conf,\n",
        "                        epsilon\n",
        "                    )\n",
        "\n",
        "                    plt.savefig(f'pgd_attack_{img_path}_eps_{int(epsilon*255)}.png')\n",
        "                    plt.close(fig)\n",
        "                    exp_diff = F.mse_loss(original_exp, perturbed_exp).item()\n",
        "                    print(f\"Explanation difference (MSE): {exp_diff:.6f}\")\n",
        "                else:\n",
        "                    print(f\"\\nEpsilon = {epsilon:.4f}: Skipped - prediction changed from {orig_class} to {adv_class}\")\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error processing {img_path}: {str(e)}\")\n",
        "            continue\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "id": "D7rGYySWAtts"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "SPlf1iDbG1oi"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}